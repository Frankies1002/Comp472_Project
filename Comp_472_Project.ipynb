{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frankies1002/Comp472_Project/blob/main/Comp_472_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2: Dataset Overview\n",
        "The CIFAR-10 dataset contains 50,000 training and 10,000 test RGB images belonging to 10 object classes.\n",
        "Images are of size 32 × 32 × 3.\n",
        "\n",
        "• In this project, you will only use 500 training images and 100 test images per class. Therefore, your first\n",
        "task is to load the dataset and use the first 500 training images, and the first 100 test images of each\n",
        "class.\n",
        "\n",
        "• The Naive Bayes, decision trees, and MLPs are not well-suited for direct application to high-dimensional\n",
        "RGB image data. Therefore, you will need to convert them into low-dimensional vectors through feature\n",
        "extraction. Pre-trained CNNs can serve as good feature extractors for image classification tasks. You\n",
        "will use a pre-trained ResNet-18 CNN to extract 512 × 1 feature vectors for the RGB images. For\n",
        "this, you will first need to resize the images to 224 × 224 × 3 and normalize them, because ResNet-18\n",
        "pre-trained on ImageNet expects the images in a certain format. You will also need to remove the last\n",
        "layer of ResNet-18. Once these steps are finished, you can pass pre-processed RGB images through the\n",
        "pre-trained ResNet-18 to extract feature vectors. More details about using pre-trained CNNs in Pytorch\n",
        "can be found here: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html.\n",
        "\n",
        "• Next, use PCA in scikit learn to further reduce the size of feature vectors from 512×1 to 50×1."
      ],
      "metadata": {
        "id": "Hw4ODUblHOE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory\n",
        "from sklearn.decomposition import PCA\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def subset_cifar10(dataset, num_per_class):\n",
        "    class_counts = defaultdict(int)\n",
        "    indices = []\n",
        "    for idx, (_, label) in enumerate(dataset):\n",
        "        if class_counts[label] < num_per_class:\n",
        "            indices.append(idx)\n",
        "            class_counts[label] += 1\n",
        "    return Subset(dataset, indices)\n",
        "\n",
        "#Acquiring data set to train and transform into 224x224x3\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "#only select 500 out of the set for train and 100 for test\n",
        "train_subset = subset_cifar10(train_set, 500)\n",
        "test_subset = subset_cifar10(test_set, 100)\n",
        "\n",
        "#dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#resnet18 part\n",
        "\n",
        "# Load Pretrained ResNet-18\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# Remove final layer (fc)\n",
        "resnet18 = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "resnet18 = resnet18.to(device)\n",
        "resnet18.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Feature Extraction Function\n",
        "def extract_features(data_loader, model, device):\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, lbls in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs).squeeze()  # Shape: [batch_size, 512]\n",
        "            features.append(outputs.cpu())\n",
        "            labels.append(lbls)\n",
        "    return torch.cat(features), torch.cat(labels)\n",
        "\n",
        "# Extract Features\n",
        "train_features, train_labels = extract_features(train_loader, resnet18, device)\n",
        "test_features, test_labels = extract_features(test_loader, resnet18, device)\n",
        "\n",
        "print(f\"Train Features Shape: {train_features.shape}\")  # Expected: [5000, 512]\n",
        "print(f\"Test Features Shape: {test_features.shape}\")    # Expected: [1000, 512]\n",
        "\n",
        "\n",
        "# Apply PCA to reduce feature size from 512 to 50\n",
        "pca = PCA(n_components=50)\n",
        "train_features_pca = pca.fit_transform(train_features.numpy())\n",
        "test_features_pca = pca.transform(test_features.numpy())\n",
        "\n",
        "print(f\"Reduced Train Features Shape: {train_features_pca.shape}\")  # Expected: [5000, 50]\n",
        "print(f\"Reduced Test Features Shape: {test_features_pca.shape}\")    # Expected: [1000, 50]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9n7c3JiHVVN",
        "outputId": "15944a6e-8f6e-48cc-d60f-c2d06158a2be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 35.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 167MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Features Shape: torch.Size([5000, 512])\n",
            "Test Features Shape: torch.Size([1000, 512])\n",
            "Reduced Train Features Shape: (5000, 50)\n",
            "Reduced Test Features Shape: (1000, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test 2-ferhaan\n"
      ],
      "metadata": {
        "id": "17cPA1gGPwRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Step 1: Load CIFAR-10 and Preprocess\n",
        "# Define preprocessing transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to 224x224 for ResNet\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize as per ImageNet\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Function to select the first N samples per class\n",
        "def select_subset(dataset, samples_per_class):\n",
        "    indices = []\n",
        "    class_counts = [0] * 10  # CIFAR-10 has 10 classes\n",
        "    for i, (_, label) in enumerate(dataset):\n",
        "        if class_counts[label] < samples_per_class:\n",
        "            indices.append(i)\n",
        "            class_counts[label] += 1\n",
        "        if sum(class_counts) == samples_per_class * 10:\n",
        "            break\n",
        "    return Subset(dataset, indices)\n",
        "\n",
        "# Select subsets of the dataset\n",
        "train_subset = select_subset(train_dataset, samples_per_class=500)\n",
        "test_subset = select_subset(test_dataset, samples_per_class=100)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Step 2: Load Pre-Trained ResNet-18 and Extract Features\n",
        "# Load the pre-trained ResNet-18 model\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "resnet18 = torch.nn.Sequential(*(list(resnet18.children())[:-1]))  # Remove the last fully connected layer\n",
        "resnet18.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Function to extract features using ResNet-18\n",
        "def extract_features(dataloader, model):\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():  # No gradients needed during feature extraction\n",
        "        for images, lbls in dataloader:\n",
        "            output = model(images)  # Pass through ResNet\n",
        "            features.append(output.squeeze().cpu().numpy())  # Extract features and move to CPU\n",
        "            labels.append(lbls.numpy())  # Save labels\n",
        "    return np.vstack(features), np.hstack(labels)\n",
        "\n",
        "# Extract features for train and test sets\n",
        "train_features, train_labels = extract_features(train_loader, resnet18)\n",
        "test_features, test_labels = extract_features(test_loader, resnet18)\n",
        "\n",
        "# Step 3: Reduce Dimensionality Using PCA\n",
        "# Apply PCA to reduce feature dimensions from 512 to 50\n",
        "pca = PCA(n_components=50)\n",
        "train_features_reduced = pca.fit_transform(train_features)\n",
        "test_features_reduced = pca.transform(test_features)\n",
        "\n",
        "# Output shapes for verification\n",
        "print(f\"Reduced Train Features Shape: {train_features_reduced.shape}\")\n",
        "print(f\"Reduced Test Features Shape: {test_features_reduced.shape}\")\n",
        "\n",
        "# Save the reduced features and labels for later use\n",
        "np.save('train_features_reduced.npy', train_features_reduced)\n",
        "np.save('train_labels.npy', train_labels)\n",
        "np.save('test_features_reduced.npy', test_features_reduced)\n",
        "np.save('test_labels.npy', test_labels)\n",
        "\n",
        "print(\"Feature extraction and dimensionality reduction completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG8MwPsPPGTf",
        "outputId": "9ae63192-c83c-4b8f-fb1c-3eb35188f19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced Train Features Shape: (5000, 50)\n",
            "Reduced Test Features Shape: (1000, 50)\n",
            "Feature extraction and dimensionality reduction completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3: Naive Bayes\n",
        "1. Implement the Gaussian Naive Bayes algorithm in Python. You are only allowed to use the basic Python\n",
        "and Numpy libraries. Fit the Naive Bayes on the training feature vectors of all 10 classes.\n",
        "2. Next, repeat the above step but using the Scikit’s Gaussian Naive Bayes classifier.\n",
        "3. Evaluate both of these models on the test set of CIFAR-10 (feature vectors of the images in the test set).\n",
        "Evaluation details are stated below in Section 7."
      ],
      "metadata": {
        "id": "2ru7OV8eHZio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory\n",
        "from sklearn.decomposition import PCA\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "#datapreparation------------------------------------------------------------------------------------------\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def subset_cifar10(dataset, num_per_class):\n",
        "    class_counts = defaultdict(int)\n",
        "    indices = []\n",
        "    for idx, (_, label) in enumerate(dataset):\n",
        "        if class_counts[label] < num_per_class:\n",
        "            indices.append(idx)\n",
        "            class_counts[label] += 1\n",
        "    return Subset(dataset, indices)\n",
        "\n",
        "#Acquiring data set to train and transform into 224x224x3\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "#only select 500 out of the set for train and 100 for test\n",
        "train_subset = subset_cifar10(train_set, 500)\n",
        "test_subset = subset_cifar10(test_set, 100)\n",
        "\n",
        "#dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#resnet18 part\n",
        "\n",
        "# Load Pretrained ResNet-18\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# Remove final layer (fc)\n",
        "resnet18 = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "resnet18 = resnet18.to(device)\n",
        "resnet18.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Feature Extraction Function\n",
        "def extract_features(data_loader, model, device):\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, lbls in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs).squeeze()  # Shape: [batch_size, 512]\n",
        "            features.append(outputs.cpu())\n",
        "            labels.append(lbls)\n",
        "    return torch.cat(features), torch.cat(labels)\n",
        "\n",
        "# Extract Features\n",
        "train_features, train_labels = extract_features(train_loader, resnet18, device)\n",
        "test_features, test_labels = extract_features(test_loader, resnet18, device)\n",
        "\n",
        "print(f\"Train Features Shape: {train_features.shape}\")  # Expected: [5000, 512]\n",
        "print(f\"Test Features Shape: {test_features.shape}\")    # Expected: [1000, 512]\n",
        "\n",
        "\n",
        "# Apply PCA to reduce feature size from 512 to 50\n",
        "pca = PCA(n_components=50)\n",
        "train_features_pca = pca.fit_transform(train_features.numpy())\n",
        "test_features_pca = pca.transform(test_features.numpy())\n",
        "\n",
        "print(f\"Reduced Train Features Shape: {train_features_pca.shape}\")  # Expected: [5000, 50]\n",
        "print(f\"Reduced Test Features Shape: {test_features_pca.shape}\")    # Expected: [1000, 50]\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------\n",
        "# Custom Gaussian Naive Bayes implementation\n",
        "class GaussianNaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.classes = None\n",
        "        self.means = {}\n",
        "        self.variances = {}\n",
        "        self.priors = {}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        for cls in self.classes:\n",
        "            X_cls = X[y == cls]\n",
        "            self.means[cls] = X_cls.mean(axis=0)\n",
        "            self.variances[cls] = X_cls.var(axis=0) + 1e-6  # Add small value to avoid division by zero\n",
        "            self.priors[cls] = X_cls.shape[0] / X.shape[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        posteriors = []\n",
        "        for cls in self.classes:\n",
        "            mean = self.means[cls]\n",
        "            var = self.variances[cls]\n",
        "            prior = np.log(self.priors[cls])\n",
        "            log_likelihood = -0.5 * np.sum(np.log(2. * np.pi * var)) - 0.5 * np.sum(((X - mean) ** 2) / var, axis=1)\n",
        "            posterior = prior + log_likelihood\n",
        "            posteriors.append(posterior)\n",
        "        return self.classes[np.argmax(posteriors, axis=0)]\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = np.mean(predictions == y)\n",
        "        return accuracy, predictions\n",
        "\n",
        "# Fit the custom Gaussian Naive Bayes model\n",
        "gnb = GaussianNaiveBayes()\n",
        "gnb.fit(train_features_pca, train_labels.numpy())\n",
        "\n",
        "# Evaluate the custom Gaussian Naive Bayes model\n",
        "accuracy, predictions = gnb.evaluate(test_features_pca, test_labels.numpy())\n",
        "\n",
        "# Print evaluation metrics\n",
        "def confusion_matrix(y_true, y_pred, classes):\n",
        "    matrix = np.zeros((len(classes), len(classes)), dtype=int)\n",
        "    for i in range(len(y_true)):\n",
        "        matrix[int(y_true[i]), int(y_pred[i])] += 1\n",
        "    return matrix\n",
        "\n",
        "def classification_report(y_true, y_pred, classes):\n",
        "    report = {}\n",
        "    for cls in classes:\n",
        "        cls = int(cls)\n",
        "        tp = np.sum((y_true == cls) & (y_pred == cls))\n",
        "        fp = np.sum((y_true != cls) & (y_pred == cls))\n",
        "        fn = np.sum((y_true == cls) & (y_pred != cls))\n",
        "        precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
        "        recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "        report[cls] = {\"Precision\": precision, \"Recall\": recall, \"F1-Score\": f1}\n",
        "    return report\n",
        "\n",
        "# Convert tensors to NumPy arrays for compatibility\n",
        "test_labels_np = test_labels.numpy()\n",
        "predictions_np = predictions  # This is already a NumPy array from GaussianNaiveBayes\n",
        "\n",
        "# Generate confusion matrix and classification report\n",
        "classes = np.unique(test_labels_np)\n",
        "conf_matrix = confusion_matrix(test_labels_np, predictions_np, classes)\n",
        "class_report = classification_report(test_labels_np, predictions_np, classes)\n",
        "\n",
        "# Output results\n",
        "print(\"Custom Gaussian Naive Bayes Accuracy:\", accuracy)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "for cls, metrics in class_report.items():\n",
        "    print(f\"Class {cls}: Precision: {metrics['Precision']:.2f}, Recall: {metrics['Recall']:.2f}, F1-Score: {metrics['F1-Score']:.2f}\")\n"
      ],
      "metadata": {
        "id": "yxiEY-cFH0JN",
        "outputId": "d1d0286d-d6cd-4ec4-849a-e5afa8e45adc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Features Shape: torch.Size([5000, 512])\n",
            "Test Features Shape: torch.Size([1000, 512])\n",
            "Reduced Train Features Shape: (5000, 50)\n",
            "Reduced Test Features Shape: (1000, 50)\n",
            "Custom Gaussian Naive Bayes Accuracy: 0.789\n",
            "\n",
            "Confusion Matrix:\n",
            " [[81  1  0  1  0  0  1  0 12  4]\n",
            " [ 3 89  0  2  0  0  0  1  0  5]\n",
            " [ 7  0 61  9  8  3 11  0  1  0]\n",
            " [ 1  0  3 74  4 10  7  1  0  0]\n",
            " [ 1  0  3  7 77  2  2  8  0  0]\n",
            " [ 0  1  4 15  3 72  2  3  0  0]\n",
            " [ 2  0  4  5  7  1 80  1  0  0]\n",
            " [ 1  1  0  5  5  6  0 81  1  0]\n",
            " [ 8  0  2  0  0  0  0  0 87  3]\n",
            " [ 5  3  0  2  0  0  0  1  2 87]]\n",
            "\n",
            "Classification Report:\n",
            "Class 0: Precision: 0.74, Recall: 0.81, F1-Score: 0.78\n",
            "Class 1: Precision: 0.94, Recall: 0.89, F1-Score: 0.91\n",
            "Class 2: Precision: 0.79, Recall: 0.61, F1-Score: 0.69\n",
            "Class 3: Precision: 0.62, Recall: 0.74, F1-Score: 0.67\n",
            "Class 4: Precision: 0.74, Recall: 0.77, F1-Score: 0.75\n",
            "Class 5: Precision: 0.77, Recall: 0.72, F1-Score: 0.74\n",
            "Class 6: Precision: 0.78, Recall: 0.80, F1-Score: 0.79\n",
            "Class 7: Precision: 0.84, Recall: 0.81, F1-Score: 0.83\n",
            "Class 8: Precision: 0.84, Recall: 0.87, F1-Score: 0.86\n",
            "Class 9: Precision: 0.88, Recall: 0.87, F1-Score: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test 2"
      ],
      "metadata": {
        "id": "UZIeUvRzSL9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load CIFAR-10 and Preprocess\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "def select_subset(dataset, samples_per_class):\n",
        "    indices = []\n",
        "    class_counts = [0] * 10\n",
        "    for i, (_, label) in enumerate(dataset):\n",
        "        if class_counts[label] < samples_per_class:\n",
        "            indices.append(i)\n",
        "            class_counts[label] += 1\n",
        "        if sum(class_counts) == samples_per_class * 10:\n",
        "            break\n",
        "    return Subset(dataset, indices)\n",
        "\n",
        "train_subset = select_subset(train_dataset, samples_per_class=500)\n",
        "test_subset = select_subset(test_dataset, samples_per_class=100)\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Step 2: Feature Extraction with ResNet-18\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "resnet18 = torch.nn.Sequential(*(list(resnet18.children())[:-1]))\n",
        "resnet18.eval()\n",
        "\n",
        "def extract_features(dataloader, model):\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, lbls in dataloader:\n",
        "            output = model(images)\n",
        "            features.append(output.squeeze().cpu().numpy())\n",
        "            labels.append(lbls.numpy())\n",
        "    return np.vstack(features), np.hstack(labels)\n",
        "\n",
        "train_features, train_labels = extract_features(train_loader, resnet18)\n",
        "test_features, test_labels = extract_features(test_loader, resnet18)\n",
        "\n",
        "# Reduce Dimensions with PCA\n",
        "pca = PCA(n_components=50)\n",
        "train_features_reduced = pca.fit_transform(train_features)\n",
        "test_features_reduced = pca.transform(test_features)\n",
        "\n",
        "# Step 3: Naive Bayes Implementation\n",
        "class GaussianNaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.means = None\n",
        "        self.variances = None\n",
        "        self.priors = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        n_features = X.shape[1]\n",
        "        self.means = np.zeros((len(self.classes), n_features))\n",
        "        self.variances = np.zeros((len(self.classes), n_features))\n",
        "        self.priors = np.zeros(len(self.classes))\n",
        "\n",
        "        for idx, cls in enumerate(self.classes):\n",
        "            X_cls = X[y == cls]\n",
        "            self.means[idx, :] = np.mean(X_cls, axis=0)\n",
        "            self.variances[idx, :] = np.var(X_cls, axis=0)\n",
        "            self.priors[idx] = X_cls.shape[0] / X.shape[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            posteriors = self._calculate_posteriors(x)\n",
        "            predictions.append(np.argmax(posteriors))\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _calculate_posteriors(self, x):\n",
        "        posteriors = []\n",
        "        for idx, cls in enumerate(self.classes):\n",
        "            prior = np.log(self.priors[idx])\n",
        "            conditional = -0.5 * np.sum(np.log(2 * np.pi * self.variances[idx]))\n",
        "            conditional -= 0.5 * np.sum(((x - self.means[idx]) ** 2) / self.variances[idx])\n",
        "            posteriors.append(prior + conditional)\n",
        "        return posteriors\n",
        "\n",
        "# Train Naive Bayes\n",
        "gnb = GaussianNaiveBayes()\n",
        "gnb.fit(train_features_reduced, train_labels)\n",
        "\n",
        "# Predict and Evaluate Naive Bayes\n",
        "nb_predictions = gnb.predict(test_features_reduced)\n",
        "\n",
        "# Confusion Matrix Visualization\n",
        "def plot_confusion_matrix(conf_matrix, title):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xticks(ticks=np.arange(10), labels=[f\"Class {i}\" for i in range(10)])\n",
        "    plt.yticks(ticks=np.arange(10), labels=[f\"Class {i}\" for i in range(10)])\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            plt.text(j, i, conf_matrix[i, j], horizontalalignment=\"center\", color=\"white\" if conf_matrix[i, j] > conf_matrix.max() / 2 else \"black\")\n",
        "    plt.show()\n",
        "\n",
        "def confusion_matrix(y_true, y_pred, num_classes):\n",
        "    matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
        "    for t, p in zip(y_true, y_pred):\n",
        "        matrix[t, p] += 1\n",
        "    return matrix\n",
        "\n",
        "nb_conf_matrix = confusion_matrix(test_labels, nb_predictions, num_classes=10)\n",
        "plot_confusion_matrix(nb_conf_matrix, title=\"Confusion Matrix - Naive Bayes\")\n",
        "\n",
        "# Evaluation Metrics\n",
        "accuracy = np.trace(nb_conf_matrix) / np.sum(nb_conf_matrix)\n",
        "print(f\"Naive Bayes Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "id": "Oai2OCEBSNC4",
        "outputId": "6b2e6956-3f2c-4d5f-d794-9b00949d868b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 39.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 157MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 79.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test 2 combines"
      ],
      "metadata": {
        "id": "G437XyAbVxhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load Preprocessed Features and Labels\n",
        "# Assuming the features and labels were saved earlier\n",
        "train_features_reduced = np.load('train_features_reduced.npy')\n",
        "train_labels = np.load('train_labels.npy')\n",
        "test_features_reduced = np.load('test_features_reduced.npy')\n",
        "test_labels = np.load('test_labels.npy')\n",
        "\n",
        "# Step 2: Train Gaussian Naive Bayes Classifier\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(train_features_reduced, train_labels)\n",
        "\n",
        "# Step 3: Predict on the Test Set\n",
        "sklearn_predictions = gnb.predict(test_features_reduced)\n",
        "\n",
        "# Step 4: Evaluate the Model\n",
        "# Confusion Matrix\n",
        "sklearn_conf_matrix = confusion_matrix(test_labels, sklearn_predictions)\n",
        "\n",
        "# Accuracy\n",
        "sklearn_accuracy = accuracy_score(test_labels, sklearn_predictions)\n",
        "print(f\"Scikit-learn Naive Bayes Accuracy: {sklearn_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Step 5: Plot Confusion Matrix\n",
        "def plot_confusion_matrix(conf_matrix, title):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xticks(ticks=np.arange(10), labels=[f\"Class {i}\" for i in range(10)])\n",
        "    plt.yticks(ticks=np.arange(10), labels=[f\"Class {i}\" for i in range(10)])\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            plt.text(j, i, conf_matrix[i, j], horizontalalignment=\"center\",\n",
        "                     color=\"white\" if conf_matrix[i, j] > conf_matrix.max() / 2 else \"black\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plot_confusion_matrix(sklearn_conf_matrix, title=\"Confusion Matrix - Scikit-learn Naive Bayes\")\n",
        "\n",
        "# Step 6: Print Per-Class Metrics\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(sklearn_conf_matrix)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "for i in range(10):\n",
        "    tp = sklearn_conf_matrix[i, i]\n",
        "    fp = sklearn_conf_matrix[:, i].sum() - tp\n",
        "    fn = sklearn_conf_matrix[i, :].sum() - tp\n",
        "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "    print(f\"Class {i}: Precision={precision:.2f}, Recall={recall:.2f}, F1-Score={f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "IkzgP1dCV4C2",
        "outputId": "6a448735-7259-4674-8f31-daabae6e4770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train_features_reduced.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c7f087930844>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Step 1: Load Preprocessed Features and Labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Assuming the features and labels were saved earlier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_features_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_features_reduced.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_labels.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_features_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_features_reduced.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_features_reduced.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4: Decision Tree\n",
        "You are only allowed to use the basic Python and Numpy libraries for all parts unless specified otherwise.\n",
        "\n",
        "1. Develop a decision tree classifier with the Gini coefficient and maximum depth of 50 and train it on the\n",
        "training set of CIFAR-10 (feature vectors).\n",
        "\n",
        "\n",
        "2. Experiment by varying the depth of the tree. Observe and document how the depth of the tree influences the model’s ability to learn and generalize from the data.\n",
        "\n",
        "3. Next, repeat step 1 using the Scikit’s implementation of a Decision Tree.\n",
        "\n",
        "4. Evaluate all of the above models on the test set of CIFAR-10 (feature vectors of the images in the test\n",
        "set)."
      ],
      "metadata": {
        "id": "0vEtS8LbHkoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Custom Decision Tree Implementation\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=50):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def gini_index(self, groups, classes):\n",
        "        # Calculate the Gini index for a split\n",
        "        n_instances = sum(len(group) for group in groups)\n",
        "        gini = 0.0\n",
        "        for group in groups:\n",
        "            size = len(group)\n",
        "            if size == 0:\n",
        "                continue\n",
        "            score = 0.0\n",
        "            y_group = group[:, -1]\n",
        "            for class_val in classes:\n",
        "                p = np.sum(y_group == class_val) / size\n",
        "                score += p * p\n",
        "            gini += (1 - score) * (size / n_instances)\n",
        "        return gini\n",
        "\n",
        "    def split(self, index, value, dataset):\n",
        "        # Split the dataset into two groups\n",
        "        left = dataset[dataset[:, index] <= value]\n",
        "        right = dataset[dataset[:, index] > value]\n",
        "        return left, right\n",
        "\n",
        "    def best_split(self, dataset, classes):\n",
        "        # Find the best split point\n",
        "        best_index, best_value, best_score, best_groups = None, None, float(\"inf\"), None\n",
        "        for index in range(dataset.shape[1] - 1):  # Exclude the label column\n",
        "            for row in dataset:\n",
        "                groups = self.split(index, row[index], dataset)\n",
        "                gini = self.gini_index(groups, classes)\n",
        "                if gini < best_score:\n",
        "                    best_index, best_value, best_score, best_groups = index, row[index], gini, groups\n",
        "        return {\"index\": best_index, \"value\": best_value, \"groups\": best_groups}\n",
        "\n",
        "    def terminal_node(self, group):\n",
        "        # Determine the terminal node value\n",
        "        labels = group[:, -1]\n",
        "        return np.bincount(labels.astype(int)).argmax()\n",
        "\n",
        "    def build_tree(self, dataset, depth, classes):\n",
        "        # Recursive tree-building\n",
        "        if depth >= self.max_depth or len(np.unique(dataset[:, -1])) == 1:\n",
        "            return self.terminal_node(dataset)\n",
        "        node = self.best_split(dataset, classes)\n",
        "        left, right = node[\"groups\"]\n",
        "        del node[\"groups\"]\n",
        "        if not left.size or not right.size:\n",
        "            return self.terminal_node(dataset)\n",
        "        node[\"left\"] = self.build_tree(left, depth + 1, classes)\n",
        "        node[\"right\"] = self.build_tree(right, depth + 1, classes)\n",
        "        return node\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Combine features and labels into one dataset\n",
        "        dataset = np.hstack((X, y.reshape(-1, 1)))\n",
        "        self.classes = np.unique(y)\n",
        "        self.tree = self.build_tree(dataset, 0, self.classes)\n",
        "\n",
        "    def predict_one(self, row, node):\n",
        "        # Predict a single instance\n",
        "        if not isinstance(node, dict):\n",
        "            return node\n",
        "        if row[node[\"index\"]] <= node[\"value\"]:\n",
        "            return self.predict_one(row, node[\"left\"])\n",
        "        else:\n",
        "            return self.predict_one(row, node[\"right\"])\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Predict all instances\n",
        "        return np.array([self.predict_one(row, self.tree) for row in X])\n",
        "\n",
        "# Data Preparation (Replace with actual data)\n",
        "np.random.seed(0)\n",
        "train_features_pca = np.random.rand(5000, 50)  # Replace with PCA-transformed training features\n",
        "train_labels = np.random.randint(0, 10, 5000)  # Replace with corresponding labels\n",
        "test_features_pca = np.random.rand(1000, 50)   # Replace with PCA-transformed test features\n",
        "test_labels = np.random.randint(0, 10, 1000)   # Replace with corresponding labels\n",
        "\n",
        "# Train the Decision Tree\n",
        "decision_tree = DecisionTree(max_depth=50)\n",
        "decision_tree.fit(train_features_pca, train_labels)\n",
        "\n",
        "# Predict on test data\n",
        "predictions = decision_tree.predict(test_features_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "def accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "def confusion_matrix(y_true, y_pred, classes):\n",
        "    matrix = np.zeros((len(classes), len(classes)), dtype=int)\n",
        "    for i in range(len(y_true)):\n",
        "        matrix[int(y_true[i]), int(y_pred[i])] += 1\n",
        "    return matrix\n",
        "\n",
        "# Calculate accuracy and confusion matrix\n",
        "test_accuracy = accuracy(test_labels, predictions)\n",
        "conf_matrix = confusion_matrix(test_labels, predictions, np.unique(test_labels))\n",
        "\n",
        "# Output results\n",
        "print(\"Decision Tree Test Accuracy:\", test_accuracy)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Experiment with varying depths\n",
        "depths = [5, 10, 20, 50]\n",
        "for depth in depths:\n",
        "    tree = DecisionTree(max_depth=depth)\n",
        "    tree.fit(train_features_pca, train_labels)\n",
        "    preds = tree.predict(test_features_pca)\n",
        "    acc = accuracy(test_labels, preds)\n",
        "    print(f\"Decision Tree Accuracy with Depth {depth}: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "JuIib6TZHfWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7b9bb1-6700-417e-80be-6bf746cb1284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Test Accuracy: 0.112\n",
            "\n",
            "Confusion Matrix:\n",
            " [[17 11  6  7 12  7 11 15 11 12]\n",
            " [ 8 13  9  8 16 10 10 14  8 15]\n",
            " [11 13 10 11  6  9 11 10 15  9]\n",
            " [ 3 14  9 13 10 11 10  8 12 13]\n",
            " [ 9 10 11 14  9  7 15  8 18 12]\n",
            " [14  9 10 16 10 10  6  8 15 13]\n",
            " [ 7 13  7  6 11  5 10  8 13 10]\n",
            " [ 4 10  7 10 10  6  8  7 12 10]\n",
            " [15  8 11  7 10  5 12  7 10  7]\n",
            " [ 5 10  8 10  7  9  8  8  4 13]]\n",
            "Decision Tree Accuracy with Depth 5: 0.0920\n",
            "Decision Tree Accuracy with Depth 10: 0.0810\n",
            "Decision Tree Accuracy with Depth 20: 0.0990\n",
            "Decision Tree Accuracy with Depth 50: 0.1120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5: Multi-Layer Perceptron (MLP)\n",
        "You can use the basic Python, Numpy, and Pytorch libraries for this part. Use the feature level test set of CIFAR-10 for all the evaluations.\n",
        "\n",
        "1. Implement a three-layer MLP (details below) and train it on the feature vectors of the CIFAR-10’s\n",
        "training set. The details of the MLP architecture are:\n",
        "- Linear(50, 512) - ReLU\n",
        "- Linear(512, 512) - BatchNorm(512) - ReLU\n",
        "- Linear(512, 10)\n",
        "You should use the cross-entropy loss torch.nn.CrossEntropyLoss for training. Also, use the SGD\n",
        "optimizer with momentum=0.9.\n",
        "\n",
        "2. Experiment by varying the depth of the network by adding or removing layers. Observe and document\n",
        "how the depth of the MLP influences the model’s ability to learn and generalize from the data.\n",
        "\n",
        "3. Vary the sizes of the hidden layers. Experiment with larger and smaller sizes. Analyze the trade-offs in\n",
        "computational cost and performance of the model"
      ],
      "metadata": {
        "id": "0Mse2Bv_Hyqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "#dataset import---------------------------------------------------------------------------------------------------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory\n",
        "from sklearn.decomposition import PCA\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def subset_cifar10(dataset, num_per_class):\n",
        "    class_counts = defaultdict(int)\n",
        "    indices = []\n",
        "    for idx, (_, label) in enumerate(dataset):\n",
        "        if class_counts[label] < num_per_class:\n",
        "            indices.append(idx)\n",
        "            class_counts[label] += 1\n",
        "    return Subset(dataset, indices)\n",
        "\n",
        "#Acquiring data set to train and transform into 224x224x3\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "#only select 500 out of the set for train and 100 for test\n",
        "train_subset = subset_cifar10(train_set, 500)\n",
        "test_subset = subset_cifar10(test_set, 100)\n",
        "\n",
        "#dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#resnet18 part\n",
        "\n",
        "# Load Pretrained ResNet-18\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# Remove final layer (fc)\n",
        "resnet18 = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "resnet18 = resnet18.to(device)\n",
        "resnet18.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Feature Extraction Function\n",
        "def extract_features(data_loader, model, device):\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, lbls in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs).squeeze()  # Shape: [batch_size, 512]\n",
        "            features.append(outputs.cpu())\n",
        "            labels.append(lbls)\n",
        "    return torch.cat(features), torch.cat(labels)\n",
        "\n",
        "# Extract Features\n",
        "train_features, train_labels = extract_features(train_loader, resnet18, device)\n",
        "test_features, test_labels = extract_features(test_loader, resnet18, device)\n",
        "\n",
        "print(f\"Train Features Shape: {train_features.shape}\")  # Expected: [5000, 512]\n",
        "print(f\"Test Features Shape: {test_features.shape}\")    # Expected: [1000, 512]\n",
        "\n",
        "\n",
        "# Apply PCA to reduce feature size from 512 to 50\n",
        "pca = PCA(n_components=50)\n",
        "train_features_pca = pca.fit_transform(train_features.numpy())\n",
        "test_features_pca = pca.transform(test_features.numpy())\n",
        "\n",
        "print(f\"Reduced Train Features Shape: {train_features_pca.shape}\")  # Expected: [5000, 50]\n",
        "print(f\"Reduced Test Features Shape: {test_features_pca.shape}\")    # Expected: [1000, 50]\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------------------------------\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "train_features_tensor = torch.tensor(train_features_pca, dtype=torch.float32)\n",
        "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
        "test_features_tensor = torch.tensor(test_features_pca, dtype=torch.float32)\n",
        "test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
        "\n",
        "# Create DataLoaders for training and testing\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(train_features_tensor, train_labels_tensor)\n",
        "test_dataset = TensorDataset(test_features_tensor, test_labels_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define the Multi-Layer Perceptron (MLP)\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size=50, hidden_size=512, output_size=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.BatchNorm1d(hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Instantiate the model, loss function, and optimizer\n",
        "input_size = 50\n",
        "hidden_size = 512\n",
        "output_size = 10\n",
        "\n",
        "model = MLP(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Training function\n",
        "def train(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(loader)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "    return np.concatenate(all_preds), np.concatenate(all_labels)\n",
        "\n",
        "# Train the MLP\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "# Evaluate the MLP\n",
        "test_preds, test_labels_np = evaluate(model, test_loader, device)\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(test_labels_np, test_preds)\n",
        "conf_matrix = confusion_matrix(test_labels_np, test_preds)\n",
        "class_report = classification_report(test_labels_np, test_preds)\n",
        "\n",
        "# Output results\n",
        "print(f\"MLP Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n"
      ],
      "metadata": {
        "id": "lOStTKufIBlj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f684144-7904-4872-b516-1414ad1e94c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Features Shape: torch.Size([5000, 512])\n",
            "Test Features Shape: torch.Size([1000, 512])\n",
            "Reduced Train Features Shape: (5000, 50)\n",
            "Reduced Test Features Shape: (1000, 50)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a6a3c0e923bd>:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
            "<ipython-input-5-a6a3c0e923bd>:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.7644\n",
            "Epoch 2/20, Loss: 0.4190\n",
            "Epoch 3/20, Loss: 0.3213\n",
            "Epoch 4/20, Loss: 0.2616\n",
            "Epoch 5/20, Loss: 0.2256\n",
            "Epoch 6/20, Loss: 0.1679\n",
            "Epoch 7/20, Loss: 0.1536\n",
            "Epoch 8/20, Loss: 0.1262\n",
            "Epoch 9/20, Loss: 0.0950\n",
            "Epoch 10/20, Loss: 0.0797\n",
            "Epoch 11/20, Loss: 0.0675\n",
            "Epoch 12/20, Loss: 0.0421\n",
            "Epoch 13/20, Loss: 0.0633\n",
            "Epoch 14/20, Loss: 0.0513\n",
            "Epoch 15/20, Loss: 0.0267\n",
            "Epoch 16/20, Loss: 0.0293\n",
            "Epoch 17/20, Loss: 0.0177\n",
            "Epoch 18/20, Loss: 0.0149\n",
            "Epoch 19/20, Loss: 0.0134\n",
            "Epoch 20/20, Loss: 0.0131\n",
            "MLP Test Accuracy: 0.8200\n",
            "\n",
            "Confusion Matrix:\n",
            " [[87  1  2  1  2  0  0  0  4  3]\n",
            " [ 3 89  0  1  0  0  0  0  0  7]\n",
            " [ 6  0 69  6  4  3  9  2  1  0]\n",
            " [ 1  0  1 74  4 11  6  2  1  0]\n",
            " [ 1  0  2  5 78  3  3  7  1  0]\n",
            " [ 0  0  6 12  3 72  2  4  1  0]\n",
            " [ 1  0  3  3  4  3 85  1  0  0]\n",
            " [ 0  0  1  3  7  3  0 86  0  0]\n",
            " [ 9  0  1  0  0  0  0  1 87  2]\n",
            " [ 2  1  0  2  0  0  0  0  2 93]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.87      0.83       100\n",
            "           1       0.98      0.89      0.93       100\n",
            "           2       0.81      0.69      0.75       100\n",
            "           3       0.69      0.74      0.71       100\n",
            "           4       0.76      0.78      0.77       100\n",
            "           5       0.76      0.72      0.74       100\n",
            "           6       0.81      0.85      0.83       100\n",
            "           7       0.83      0.86      0.85       100\n",
            "           8       0.90      0.87      0.88       100\n",
            "           9       0.89      0.93      0.91       100\n",
            "\n",
            "    accuracy                           0.82      1000\n",
            "   macro avg       0.82      0.82      0.82      1000\n",
            "weighted avg       0.82      0.82      0.82      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6: Convolutional Neural Network\n",
        "You can use the basic Python, Numpy, and Pytorch libraries for this project. Perform your evaluations on the\n",
        "test images of CIFAR-10.\n",
        "\n",
        "1. Implement and train a VGG11 net on the training set of CIFAR-10. Use the training images directly\n",
        "for this part. VGG11 was an earlier version of VGG16 and can be found as model A in Table 1 of this\n",
        "paper, whose Section 2.1 also gives you all the details about each layer.\n",
        "For your convenience, we list the details of the VGG11 architecture here. The convolutional lay-\n",
        "ers are denoted as Conv(number of input channels, number of output channels, kernel size,\n",
        "stride, padding); the batch normalization layers are denoted as BatchNorm(number of channels);\n",
        "the max-pooling layers are denoted as MaxPool(kernel size, stride); the fully-connected layers are\n",
        "denoted as Linear(number of input features, number of output features); the drop out layers\n",
        "are denoted as Dropout(dropout ratio):\n",
        "- Conv(001, 064, 3, 1, 1) - BatchNorm(064) - ReLU - MaxPool(2, 2)\n",
        "- Conv(064, 128, 3, 1, 1) - BatchNorm(128) - ReLU - MaxPool(2, 2)\n",
        "- Conv(128, 256, 3, 1, 1) - BatchNorm(256) - ReLU\n",
        "- Conv(256, 256, 3, 1, 1) - BatchNorm(256) - ReLU - MaxPool(2, 2)\n",
        "- Conv(256, 512, 3, 1, 1) - BatchNorm(512) - ReLU\n",
        "- Conv(512, 512, 3, 1, 1) - BatchNorm(512) - ReLU - MaxPool(2, 2)\n",
        "- Conv(512, 512, 3, 1, 1) - BatchNorm(512) - ReLU\n",
        "- Conv(512, 512, 3, 1, 1) - BatchNorm(512) - ReLU - MaxPool(2, 2)\n",
        "- Linear(0512, 4096) - ReLU - Dropout(0.5)\n",
        "- Linear(4096, 4096) - ReLU - Dropout(0.5)\n",
        "- Linear(4096, 10)\n",
        "Concordia University COMP472 Fall 2024\n",
        "You should use the following in your training process unless specified otherwise: cross-entropy loss\n",
        "torch.nn.CrossEntropyLoss, and optimize using SGD optimizer with momentum=0.9.\n",
        "2. Experiment by adding or removing convolutional layers in your architecture. Observe and document how\n",
        "the depth of the network influences the model’s ability to learn and generalize from the data.\n",
        "3. Adjust the kernel sizes used in your convolutional layers. Experiment with larger kernels (e.g., 5 × 5 or 7\n",
        "× 7) as well as smaller ones (e.g., 2 × 2 or 3 × 3). Analyze the trade-offs in terms of spatial granularity\n",
        "versus computational cost and how different kernel sizes influence the recognition of broader features\n",
        "versus finer details."
      ],
      "metadata": {
        "id": "hi2QHe1cICr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the VGG11 architecture\n",
        "class VGG11(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG11, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Block 4\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Block 5\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = VGG11(num_classes=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, loader, criterion, optimizer, device, epochs=20):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(loader):.4f}\")\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy, all_preds, all_labels\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, criterion, optimizer, device, epochs=20)\n",
        "\n",
        "# Evaluate the model\n",
        "test_accuracy, test_preds, test_labels = evaluate_model(model, test_loader, device)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
        "class_report = classification_report(test_labels, test_preds)\n",
        "\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n"
      ],
      "metadata": {
        "id": "nC4CyG8hIKJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4758ca7b-51c7-4237-e891-983eb08b1859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/20, Loss: 1.2864\n",
            "Epoch 2/20, Loss: 0.8354\n",
            "Epoch 3/20, Loss: 0.6441\n",
            "Epoch 4/20, Loss: 0.5134\n",
            "Epoch 5/20, Loss: 0.4155\n",
            "Epoch 6/20, Loss: 0.3332\n",
            "Epoch 7/20, Loss: 0.2790\n",
            "Epoch 8/20, Loss: 0.2169\n",
            "Epoch 9/20, Loss: 0.1738\n",
            "Epoch 10/20, Loss: 0.1432\n",
            "Epoch 11/20, Loss: 0.1125\n",
            "Epoch 12/20, Loss: 0.0927\n",
            "Epoch 13/20, Loss: 0.0771\n",
            "Epoch 14/20, Loss: 0.0698\n",
            "Epoch 15/20, Loss: 0.0587\n",
            "Epoch 16/20, Loss: 0.0509\n",
            "Epoch 17/20, Loss: 0.0437\n",
            "Epoch 18/20, Loss: 0.0523\n",
            "Epoch 19/20, Loss: 0.0350\n",
            "Epoch 20/20, Loss: 0.0281\n",
            "Test Accuracy: 0.8414\n",
            "\n",
            "Confusion Matrix:\n",
            " [[875  11  30  12   6   6   8   6  30  16]\n",
            " [  3 930   2   3   1   3   7   0  12  39]\n",
            " [ 43   1 771  37  64  28  32  16   7   1]\n",
            " [ 16   4  62 683  43 115  46  20   4   7]\n",
            " [  7   2  29  41 874  14  20  10   3   0]\n",
            " [ 10   4  33 112  35 740  21  38   2   5]\n",
            " [  3   0  24  33  24   6 901   5   4   0]\n",
            " [ 10   0  18  27  50  17   5 860   5   8]\n",
            " [ 52  15   7   5   4   3   4   2 894  14]\n",
            " [ 13  57   9   8   2   2   4   8  11 886]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86      1000\n",
            "           1       0.91      0.93      0.92      1000\n",
            "           2       0.78      0.77      0.78      1000\n",
            "           3       0.71      0.68      0.70      1000\n",
            "           4       0.79      0.87      0.83      1000\n",
            "           5       0.79      0.74      0.77      1000\n",
            "           6       0.86      0.90      0.88      1000\n",
            "           7       0.89      0.86      0.88      1000\n",
            "           8       0.92      0.89      0.91      1000\n",
            "           9       0.91      0.89      0.90      1000\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}